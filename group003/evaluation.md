# CogniChip Hackathon Evaluation Receipt — group003

## Submission Overview
- Team folder: `group003`
- Slides: `slides/AI-Guided Memory Hierarchy Design  For Edge LLM Inference.pdf`
- Video: `video/jet2holiday-presentation.mp4`
- Code/Repo: `src/lm_memory_controller/` — SystemVerilog RTL (5 modules), 8 testbenches, Python analytical model, DEPS.yml, Cognichip EDA simulation logs (tb_llm_memory_controller.txt, tb_llm_memory_controller_comparison.txt, tb_gemm_traffic.txt), FST waveform
- Evidence completeness: **High** — multiple confirmed Cognichip EDA runs with TEST PASSED results, FST waveform, baseline-vs-optimized benchmark data, and detailed analytical model cross-validation framework.

## Score Summary
| Criterion | Score | Max |
|---|---:|---:|
| Technical Correctness | 25 | 30 |
| Cognichip Platform Usage | 17 | 20 |
| Innovation & Creativity | 12 | 15 |
| Clarity — Slides | 7 | 10 |
| Clarity — Video | 5 | 10 |
| Clarity — Repo Organization | 5 | 5 |
| Potential Real-World Impact | 8 | 10 |
| Bonus — FPGA/Tiny Tapeout | 0 | 10 |
| **Total** | **79** | **110** |

## Detailed Evaluation

### A) Technical Correctness (25/30)
- Strengths:
  - **Confirmed Cognichip EDA passing runs** for three testbenches: `tb_llm_memory_controller` (4/4 tests, including perf counters, 4-tile sequence, writeback), `tb_llm_memory_controller_comparison` (baseline vs optimized, **1.23× speedup, 8.81% compute efficiency gain**), and `tb_gemm_traffic` (PASS).
  - `TESTING_REPORT.md` documents 2 additional testbenches (tb_config_regs 10/10 ✅, tb_tile_scheduler 6/6 ✅) verified on Cognichip ACI.
  - FST waveform file (`tb_llm_memory_controller_comparison.fst`) generated by Cognichip Verilator run.
  - Analytical model cross-validated against RTL using `cross_validate.py` with ±15% cycle, ±5% DRAM tolerances; PERF output format (`PERF: gemm=... cycles=... dram_reads=...`) is reproducible.
  - `CHANGELOG.md` documents specific RTL bug fixes (negedge skid buffer for posedge race condition, 3-stage SRAM read pipeline) with root cause analysis.
  - Performance results: 56.7 ms decode / 674 ms prefill full-model latency; double-buffering yields 1.61–1.62× speedup.
- Weaknesses / Missing evidence:
  - `tb_dram_prefetch_engine`, `tb_sram_bank_arbiter`, and `tb_dynamic_reconfig` are listed as "Pending ACI verification" in TESTING_REPORT — simulation logs for these are not in the repository.
  - `tb_llm_memory_controller_comparison.txt` ends with `$finish` (no explicit PASS/FAIL assertion); some results could be unreported failures.
  - DRAM BW utilization shows 0.00% in the comparison benchmark, which may indicate a modeling gap.
- Key evidence:
  - (src/lm_memory_controller/analytical_model/tb_llm_memory_controller.txt — "TEST PASSED", 4/4 tests, perf counters cycle_count=576)
  - (src/lm_memory_controller/analytical_model/tb_llm_memory_controller_comparison.txt — 1.23× speedup, Verilator 0 errors)
  - (src/lm_memory_controller/analytical_model/tb_gemm_traffic.txt — "TEST PASSED")
  - (src/lm_memory_controller/tb_llm_memory_controller_comparison.fst — Cognichip-generated waveform)
  - (src/lm_memory_controller/lm_memory_controller_Cognichip/TESTING_REPORT.md — tb_config_regs 10/10 ✅, tb_tile_scheduler 6/6 ✅)

### B) Effective Use of the Cognichip Platform (17/20)
- Strengths:
  - `DEPS.yml` defines 8 named simulation targets for OpenCOS EDA (`eda sim --tool verilator`).
  - Simulation log files explicitly show the full Cognichip EDA invocation with tool version (`OpenCOS EDA`, `Verilator 5.038`) and run UUIDs.
  - Team demonstrates iterative use: CHANGELOG documents a specific bug-fix cycle on the Cognichip platform.
  - `AGENTS.md` present, indicating AI-assisted design and validation workflow.
  - `README.md` instructs users to run synthesis/simulation via "Cognichip platform."
  - Cross-validation script (`cross_validate.py`) reads Cognichip PERF log output, showing tight integration.
- Weaknesses / Missing evidence:
  - No Cognichip synthesis / place-and-route results; only simulation was used.
  - 3 of 8 planned testbenches still pending ACI verification at submission time.
- Key evidence:
  - (src/lm_memory_controller/analytical_model/tb_llm_memory_controller.txt — full OpenCOS EDA log with UUID `a7b1e63b-...`)
  - (src/lm_memory_controller/DEPS.yml — 8 sim targets)
  - (src/lm_memory_controller/lm_memory_controller_Cognichip/CHANGELOG.md — platform-specific negedge skid fix)

### C) Innovation & Creativity (12/15)
- Strengths:
  - **Dynamic per-layer reconfiguration** — 4-entry preset table (16 registers) for automatic tiling strategy switching between attention/FFN layers with zero software overhead; not a trivial feature.
  - **Cross-validated analytical model** paired with RTL — ~14,000 tiling configurations swept for Qwen3-8B across decode and prefill regimes.
  - **Negedge skid buffer** for Verilator-safe request capture is an insightful micro-architectural fix.
  - Quantized (INT4/INT8) edge inference targeting is highly timely.
- Weaknesses:
  - The core GEMM tiling + double-buffering concept is well-known in deep-learning accelerator literature; novelty is in the specific integration and the dynamic reconfiguration feature.
  - DRAM BW utilization at 0.00% in the benchmark suggests the compute-bound regime may not be fully exercised.
- Key evidence:
  - (src/lm_memory_controller/README.md — 4-entry preset table, 1-cycle reconfiguration)
  - (src/lm_memory_controller/analytical_model/FINDINGS.md — 1.62× double-buffering speedup, 99.7% MAC utilization in prefill)

### D) Clarity of Presentation (17/25)
#### D1) Slides clarity (7/10)
- Notes: PDF present, descriptive title "AI-Guided Memory Hierarchy Design For Edge LLM Inference" — well scoped. Cannot parse internally; score reflects presence and quality inferred from the high-quality code documentation.
- Evidence: (slides/AI-Guided Memory Hierarchy Design  For Edge LLM Inference.pdf)

#### D2) Video clarity (5/10)
- Notes: MP4 present. Filename `jet2holiday-presentation.mp4` is non-descriptive (possibly a repurposed file) — reduces confidence in video quality. Cannot parse content.
- Evidence: (video/jet2holiday-presentation.mp4)

#### D3) Repo organization (5/5)
- Notes: Exemplary — README.md (quick-start + cross-validation usage), ARCHITECTURE.md (mermaid block diagrams, FSM state tables), AGENTS.md, CHANGELOG.md, TESTING_REPORT.md, FINDINGS.md, pyproject.toml for Python dependencies. Code split into rtl/ and tb/ subdirectories. DEPS.yml complete.
- Evidence: (src/lm_memory_controller/README.md, ARCHITECTURE.md, lm_memory_controller_Cognichip/TESTING_REPORT.md)

### E) Potential Real-World Impact (8/10)
- Notes: Edge LLM inference on resource-constrained SoCs (2 MB SRAM, LPDDR5) is an active and commercially relevant problem. A 1.62× double-buffering speedup and dynamic per-layer reconfiguration with zero software overhead are directly deployable optimizations. The analytical model + RTL co-design methodology is reproducible and transferable. Slightly limited by lack of synthesis/PPA evidence.
- Evidence: (src/lm_memory_controller/analytical_model/FINDINGS.md — 56.7 ms decode latency, 1.62× speedup)

### Bonus) FPGA / Tiny Tapeout Targeting (+0/10)
- Notes: No FPGA target, no constraints file, no area/timing estimate, no Tiny Tapeout integration. README explicitly scopes to Cognichip ACI simulation only.
- Evidence: *(none)*

## Final Recommendation
- Overall verdict: **Strong submission — best-evidenced code in this hackathon cohort.**
- The team delivered a complete, multi-module RTL design with confirmed Cognichip EDA passing simulations, quantitative performance comparisons (1.23× speedup in benchmark, 1.62× analytically), and an unusually thorough analytical/RTL co-validation framework. The main gap is 3 unverified testbenches and absence of synthesis results.

## Actionable Feedback (Most Important Improvements)
1. **Complete the pending testbench runs**: Push `tb_dram_prefetch_engine`, `tb_sram_bank_arbiter`, and `tb_dynamic_reconfig` Cognichip logs to the repository before final submission to fully close the verification loop.
2. **Obtain synthesis/PPA estimates**: Running Cognichip synthesis flow to obtain area and timing at a target frequency (e.g., 500 MHz) would unlock the FPGA/Tapeout bonus and significantly strengthen the real-world impact section.
3. **Fix video filename**: Rename `jet2holiday-presentation.mp4` to a descriptive name matching the project; first impressions matter.

## Issues (If Any)
- PDF slides cannot be parsed in this environment; scored based on presence and code documentation quality.
- Video filename `jet2holiday-presentation.mp4` is non-descriptive; may reduce accessibility for reviewers.
- 3 of 8 planned testbenches (`tb_dram_prefetch_engine`, `tb_sram_bank_arbiter`, `tb_dynamic_reconfig`) have no Cognichip simulation log in the repository.
- DRAM BW utilization shows 0.00% in the comparison benchmark — should be investigated/explained.
