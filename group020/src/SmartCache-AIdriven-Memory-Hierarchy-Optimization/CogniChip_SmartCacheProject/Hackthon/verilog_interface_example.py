"""
Verilog/SystemVerilog Interface Generator
==========================================
Automatically generate parameterized cache RTL modules from
SmartCache optimization results.

This module bridges the gap between Python optimization and
hardware implementation, enabling seamless translation of
optimal configurations into synthesizable RTL.
"""

import json
import math
from typing import Dict


class VerilogCacheGenerator:
    """
    Generate parameterized Verilog cache module from optimization results.
    
    Features:
    - Automatic parameter calculation
    - Configurable interface
    - LRU replacement policy logic
    - Modular structure for easy integration
    """
    
    def __init__(self, config: Dict):
        """
        Initialize generator with cache configuration.
        
        Parameters:
        -----------
        config : dict
            Cache configuration from SmartCache optimizer
            Keys: cache_size, block_size, associativity
        """
        self.cache_size = config['cache_size']
        self.block_size = config['block_size']
        self.associativity = config['associativity']
        
        # Calculate derived parameters
        self.num_blocks = self.cache_size // self.block_size
        self.num_sets = self.num_blocks // self.associativity
        self.offset_bits = int(math.log2(self.block_size))
        self.index_bits = int(math.log2(self.num_sets))
        self.addr_width = 32  # Assume 32-bit addressing
        self.tag_bits = self.addr_width - self.index_bits - self.offset_bits
        self.data_width = 32  # 32-bit data
    
    def generate_module_header(self) -> str:
        """Generate SystemVerilog module header with parameters."""
        return f'''//==============================================================================
// AI-Optimized Cache Memory Module
// Generated by SmartCache Framework
//==============================================================================
// Configuration:
//   Cache Size:    {self.cache_size} bytes ({self.cache_size // 1024} KB)
//   Block Size:    {self.block_size} bytes
//   Associativity: {self.associativity}-way set associative
//   Number of Sets: {self.num_sets}
//   LRU Replacement Policy
//==============================================================================

module cache_memory #(
    // Primary cache parameters (from SmartCache optimization)
    parameter CACHE_SIZE   = {self.cache_size},
    parameter BLOCK_SIZE   = {self.block_size},
    parameter ASSOCIATIVITY = {self.associativity},
    
    // Derived parameters (automatically calculated)
    parameter NUM_SETS     = {self.num_sets},
    parameter NUM_BLOCKS   = {self.num_blocks},
    
    // Address field widths
    parameter ADDR_WIDTH   = {self.addr_width},
    parameter OFFSET_BITS  = {self.offset_bits},
    parameter INDEX_BITS   = {self.index_bits},
    parameter TAG_BITS     = {self.tag_bits},
    
    // Data width
    parameter DATA_WIDTH   = {self.data_width}
) (
    // Clock and reset
    input  wire                       clk,
    input  wire                       rst_n,
    
    // Memory interface
    input  wire [ADDR_WIDTH-1:0]     addr,
    input  wire                       read_enable,
    input  wire                       write_enable,
    input  wire [DATA_WIDTH-1:0]     write_data,
    output reg  [DATA_WIDTH-1:0]     read_data,
    
    // Status outputs
    output reg                        hit,
    output reg                        miss,
    output wire                       ready
);
'''
    
    def generate_internal_signals(self) -> str:
        """Generate internal signal declarations."""
        lru_bits = int(math.log2(self.associativity)) if self.associativity > 1 else 1
        
        return f'''
    //==========================================================================
    // Internal Signals
    //==========================================================================
    
    // Address field extraction
    wire [OFFSET_BITS-1:0] offset;
    wire [INDEX_BITS-1:0]  index;
    wire [TAG_BITS-1:0]    tag;
    
    assign offset = addr[OFFSET_BITS-1:0];
    assign index  = addr[OFFSET_BITS +: INDEX_BITS];
    assign tag    = addr[ADDR_WIDTH-1 : OFFSET_BITS+INDEX_BITS];
    
    // Cache storage arrays
    reg [TAG_BITS-1:0]     tag_array    [0:NUM_SETS-1][0:ASSOCIATIVITY-1];
    reg [DATA_WIDTH-1:0]   data_array   [0:NUM_SETS-1][0:ASSOCIATIVITY-1][0:BLOCK_SIZE/4-1];
    reg                     valid_array  [0:NUM_SETS-1][0:ASSOCIATIVITY-1];
    
    // LRU tracking (simplified counter-based)
    reg [{lru_bits}-1:0]   lru_counter  [0:NUM_SETS-1][0:ASSOCIATIVITY-1];
    
    // Hit detection
    wire [ASSOCIATIVITY-1:0] way_hit;
    wire                      cache_hit;
    integer                   hit_way;
    integer                   lru_way;
    
    assign ready = 1'b1;  // Single-cycle access for this simple model
    
    //==========================================================================
    // Hit Detection Logic
    //==========================================================================
    
    genvar way;
    generate
        for (way = 0; way < ASSOCIATIVITY; way = way + 1) begin : hit_detection
            assign way_hit[way] = valid_array[index][way] && 
                                  (tag_array[index][way] == tag);
        end
    endgenerate
    
    assign cache_hit = |way_hit;
'''
    
    def generate_read_logic(self) -> str:
        """Generate cache read logic."""
        return '''
    //==========================================================================
    // Read Logic
    //==========================================================================
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            hit <= 1'b0;
            miss <= 1'b0;
            read_data <= {DATA_WIDTH{1'b0}};
        end else begin
            if (read_enable) begin
                if (cache_hit) begin
                    // Cache hit - return data from matching way
                    hit <= 1'b1;
                    miss <= 1'b0;
                    
                    // Find which way hit (priority encoder)
                    for (hit_way = 0; hit_way < ASSOCIATIVITY; hit_way = hit_way + 1) begin
                        if (way_hit[hit_way]) begin
                            read_data <= data_array[index][hit_way][offset[OFFSET_BITS-1:2]];
                        end
                    end
                    
                end else begin
                    // Cache miss
                    hit <= 1'b0;
                    miss <= 1'b1;
                    read_data <= {DATA_WIDTH{1'b0}};
                end
            end else begin
                hit <= 1'b0;
                miss <= 1'b0;
            end
        end
    end
'''
    
    def generate_lru_logic(self) -> str:
        """Generate LRU replacement policy logic."""
        lru_bits = int(math.log2(self.associativity)) if self.associativity > 1 else 1
        
        return f'''
    //==========================================================================
    // LRU Update Logic (Simplified Counter-Based)
    //==========================================================================
    // Each access increments the counter for accessed way
    // Replacement chooses way with smallest counter value
    
    integer set_idx, way_idx, word_idx;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            // Initialize all arrays
            for (set_idx = 0; set_idx < NUM_SETS; set_idx = set_idx + 1) begin
                for (way_idx = 0; way_idx < ASSOCIATIVITY; way_idx = way_idx + 1) begin
                    valid_array[set_idx][way_idx] <= 1'b0;
                    tag_array[set_idx][way_idx] <= {{TAG_BITS{{1'b0}}}};
                    lru_counter[set_idx][way_idx] <= {{lru_bits}}{{1'b0}};
                    
                    for (word_idx = 0; word_idx < BLOCK_SIZE/4; word_idx = word_idx + 1) begin
                        data_array[set_idx][way_idx][word_idx] <= {{DATA_WIDTH{{1'b0}}}};
                    end
                end
            end
            
        end else begin
            // Update LRU on read/write
            if (read_enable || write_enable) begin
                if (cache_hit) begin
                    // Update LRU for hit way
                    for (way_idx = 0; way_idx < ASSOCIATIVITY; way_idx = way_idx + 1) begin
                        if (way_hit[way_idx]) begin
                            lru_counter[index][way_idx] <= lru_counter[index][way_idx] + 1;
                        end
                    end
                    
                end else begin
                    // Cache miss - find LRU way for replacement
                    lru_way = 0;
                    for (way_idx = 1; way_idx < ASSOCIATIVITY; way_idx = way_idx + 1) begin
                        if (lru_counter[index][way_idx] < lru_counter[index][lru_way]) begin
                            lru_way = way_idx;
                        end
                    end
                    
                    // Allocate in LRU way
                    valid_array[index][lru_way] <= 1'b1;
                    tag_array[index][lru_way] <= tag;
                    lru_counter[index][lru_way] <= lru_counter[index][lru_way] + 1;
                    
                    // In real implementation, would fetch block from memory
                    // Here we just mark as valid
                end
            end
            
            // Handle writes
            if (write_enable && cache_hit) begin
                for (way_idx = 0; way_idx < ASSOCIATIVITY; way_idx = way_idx + 1) begin
                    if (way_hit[way_idx]) begin
                        data_array[index][way_idx][offset[OFFSET_BITS-1:2]] <= write_data;
                    end
                end
            end
        end
    end
'''
    
    def generate_module_footer(self) -> str:
        """Generate module closing."""
        return '''
endmodule

//==============================================================================
// End of AI-Optimized Cache Module
//==============================================================================
'''
    
    def generate_testbench_template(self, module_name: str = "cache_memory") -> str:
        """Generate basic testbench template."""
        return f'''//==============================================================================
// Cache Memory Testbench
// Tests the AI-optimized cache configuration
//==============================================================================

`timescale 1ns / 1ps

module tb_{module_name};

    // Parameters (match DUT)
    localparam ADDR_WIDTH = {self.addr_width};
    localparam DATA_WIDTH = {self.data_width};
    
    // Clock and reset
    reg clk;
    reg rst_n;
    
    // DUT interface
    reg  [ADDR_WIDTH-1:0] addr;
    reg                   read_enable;
    reg                   write_enable;
    reg  [DATA_WIDTH-1:0] write_data;
    wire [DATA_WIDTH-1:0] read_data;
    wire                  hit;
    wire                  miss;
    wire                  ready;
    
    // Performance counters
    integer hit_count = 0;
    integer miss_count = 0;
    integer total_accesses = 0;
    real miss_rate;
    
    // Instantiate DUT
    {module_name} dut (
        .clk(clk),
        .rst_n(rst_n),
        .addr(addr),
        .read_enable(read_enable),
        .write_enable(write_enable),
        .write_data(write_data),
        .read_data(read_data),
        .hit(hit),
        .miss(miss),
        .ready(ready)
    );
    
    // Clock generation (10ns period = 100MHz)
    initial begin
        clk = 0;
        forever #5 clk = ~clk;
    end
    
    // Test sequence
    initial begin
        // Initialize
        rst_n = 0;
        read_enable = 0;
        write_enable = 0;
        addr = 0;
        write_data = 0;
        
        // Reset
        #20 rst_n = 1;
        #10;
        
        // Test: Sequential access pattern
        $display("==============================================");
        $display("Test 1: Sequential Access");
        $display("==============================================");
        
        repeat (100) begin
            @(posedge clk);
            read_enable <= 1;
            addr <= addr + 4;  // 4-byte stride
            
            @(posedge clk);
            total_accesses = total_accesses + 1;
            if (hit) hit_count = hit_count + 1;
            if (miss) miss_count = miss_count + 1;
            
            read_enable <= 0;
            @(posedge clk);
        end
        
        // Report results
        miss_rate = (miss_count * 100.0) / total_accesses;
        $display("\\nResults:");
        $display("  Total Accesses: %0d", total_accesses);
        $display("  Hits:  %0d", hit_count);
        $display("  Misses: %0d", miss_count);
        $display("  Miss Rate: %.2f%%", miss_rate);
        
        #100;
        $finish;
    end
    
    // Waveform dump
    initial begin
        $dumpfile("cache_tb.vcd");
        $dumpvars(0, tb_{module_name});
    end

endmodule
'''
    
    def generate_complete_module(self) -> str:
        """Generate complete cache module with all components."""
        return (self.generate_module_header() +
                self.generate_internal_signals() +
                self.generate_read_logic() +
                self.generate_lru_logic() +
                self.generate_module_footer())
    
    def save_to_file(self, filename: str = "cache_memory.sv"):
        """Save generated module to file."""
        with open(filename, 'w') as f:
            f.write(self.generate_complete_module())
        print(f"âœ“ Generated Verilog module: {filename}")
    
    def save_testbench(self, filename: str = "tb_cache_memory.sv"):
        """Save testbench to file."""
        with open(filename, 'w') as f:
            f.write(self.generate_testbench_template())
        print(f"âœ“ Generated testbench: {filename}")


def generate_from_optimization_result(results_file: str = 'experiment_results.json',
                                     workload: str = None):
    """
    Generate Verilog modules from SmartCache optimization results.
    
    Parameters:
    -----------
    results_file : str
        JSON file with optimization results
    workload : str
        Specific workload to generate for (if None, generates for best overall)
    """
    print("="*70)
    print("ðŸ”§ VERILOG GENERATION FROM SMARTCACHE RESULTS")
    print("="*70)
    
    # Load results
    with open(results_file, 'r') as f:
        results = json.load(f)
    
    print(f"âœ“ Loaded results from {results_file}\n")
    
    # Select configuration
    if workload and workload in results['optimized']:
        config = results['optimized'][workload]['best_config']
        output_prefix = f"cache_{workload}"
        print(f"Generating for workload: {workload}")
    else:
        # Use first workload as example
        first_workload = list(results['optimized'].keys())[0]
        config = results['optimized'][first_workload]['best_config']
        output_prefix = f"cache_{first_workload}"
        print(f"Generating for workload: {first_workload} (first in results)")
    
    print(f"\nOptimal Configuration:")
    print(f"  Cache Size:    {config['cache_size']} B ({config['cache_size']//1024} KB)")
    print(f"  Block Size:    {config['block_size']} B")
    print(f"  Associativity: {config['associativity']}-way")
    print(f"  Miss Rate:     {config['miss_rate']:.4f}")
    print()
    
    # Generate Verilog
    generator = VerilogCacheGenerator(config)
    generator.save_to_file(f"{output_prefix}.sv")
    generator.save_testbench(f"tb_{output_prefix}.sv")
    
    print("\n" + "="*70)
    print("âœ… VERILOG GENERATION COMPLETE")
    print("="*70)
    print(f"\nGenerated files:")
    print(f"  1. {output_prefix}.sv - Cache module")
    print(f"  2. tb_{output_prefix}.sv - Testbench")
    print("\nNext steps:")
    print(f"  1. Simulate: iverilog -g2012 {output_prefix}.sv tb_{output_prefix}.sv")
    print(f"  2. Run: ./a.out")
    print(f"  3. View waveform: gtkwave cache_tb.vcd")
    print("="*70)


if __name__ == "__main__":
    import sys
    
    print("Verilog Interface Generator - Demonstration")
    print()
    
    # Check if results file exists
    if len(sys.argv) > 1:
        results_file = sys.argv[1]
        workload = sys.argv[2] if len(sys.argv) > 2 else None
        generate_from_optimization_result(results_file, workload)
    else:
        # Demo with example configuration
        print("Demo mode: Using example configuration")
        print("(Run SmartCache experiments first, then use: python verilog_interface_example.py experiment_results.json)\n")
        
        example_config = {
            'cache_size': 16384,
            'block_size': 64,
            'associativity': 4,
            'miss_rate': 0.183
        }
        
        generator = VerilogCacheGenerator(example_config)
        generator.save_to_file("example_cache.sv")
        generator.save_testbench("tb_example_cache.sv")
        
        print("\nâœ“ Generated example files:")
        print("  - example_cache.sv")
        print("  - tb_example_cache.sv")
